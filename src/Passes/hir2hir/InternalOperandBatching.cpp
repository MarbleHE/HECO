
#include "heco/Passes/hir2hir/InternalOperandBatching.h"
#include "heco/IR/FHE/FHEDialect.h"
#include "llvm/ADT/APSInt.h"
#include "mlir/Dialect/Affine/IR/AffineOps.h"
#include "mlir/Dialect/Func/IR/FuncOps.h"
#include "mlir/Dialect/SCF/IR/SCF.h"
#include "mlir/Dialect/Tensor/IR/Tensor.h"
#include "mlir/Transforms/DialectConversion.h"

using namespace mlir;
using namespace heco;

void InternalOperandBatchingPass::getDependentDialects(mlir::DialectRegistry &registry) const
{
    registry
        .insert<fhe::FHEDialect, affine::AffineDialect, func::FuncDialect, scf::SCFDialect, tensor::TensorDialect>();
}

template <typename OpType>
LogicalResult internalBatchArithmeticOperation(
    IRRewriter &rewriter, MLIRContext *context, OpType op, Value use, int target_slot)
{
    if (auto result_bst = op.getType().template dyn_cast_or_null<fhe::BatchedSecretType>())
    {
        auto slot_count = result_bst.getSize();

        // llvm::outs() << "Attempting Internal Batching (slout_count = " << slot_count
        //              << ", target_slot = " << target_slot << ") for ";
        // op.print(llvm::outs());
        // llvm::outs() << "\n";

        /// Helper Struct for uses
        struct BatchingUse
        {
            int index = -1;
            Value occurrence;
            BatchingUse(int index, Value occurrence) : index(index), occurrence(occurrence){};
        };

        /// List of used (Batched type) operand inputs' origins and the indices accessed in each one
        typedef llvm::SmallMapVector<Value, std::vector<BatchingUse>, 1> OriginMap;
        OriginMap originMap;

        auto addOriginUse = [&](Value o, int index, Value occurrence) {
            if (originMap.find(o) != originMap.end())
                originMap.find(o)->second.push_back(BatchingUse(index, occurrence));
            else
                originMap.insert({ o, { BatchingUse(index, occurrence) } });
        };

        // collect origin information
        for (auto it = op->operand_begin(); it != op.operand_end(); ++it)
        {
            if (auto bst = (*it).getType().template dyn_cast_or_null<fhe::BatchedSecretType>())
            {
                if (auto r_op = (*it).template getDefiningOp<fhe::RotateOp>())
                {
                    addOriginUse(r_op.getX(), r_op.getI() - target_slot, *it);
                }
                else if (auto c_op = (*it).template getDefiningOp<fhe::ConstOp>())
                {
                    // Constant Ops can be realized to whatever slot we want them to be in
                    addOriginUse(*it, -1, *it);
                }
                else
                {
                    // If it's a vector generated by some other means, we only care about the element at target_slot
                    addOriginUse(*it, target_slot, *it);
                }
            }
            else
            {
                // Plaintext inputs can be realized to whatever slot we want them to be in
                addOriginUse(*it, -1, *it);
            }
        }

        // for (auto el : originMap)
        // {
        //     std::sort(el.second.begin(), el.second.end(), [](const BatchingUse &a, const BatchingUse &b) -> bool {
        //         return a.index < b.index;
        //     });
        //
        //     llvm::outs() << "\t\tindices of ";
        //     el.first.print(llvm::outs());
        //     llvm::outs() << " : ";
        //     for (auto i : el.second)
        //     {
        //         llvm::outs() << i.index << ", ";
        //     }
        //     llvm::outs() << '\n';
        // }

        for (auto el : originMap)
        {
            auto origin = el.first;

            // llvm::outs() << "\tTrying to combine occurences of indices from: ";
            // origin.print(llvm::outs());
            // llvm::outs() << '\n';

            // Check if its the indices form a contiguos block
            // Based on https://stackoverflow.com/a/73081678/2227414 extended to conesecutive number check
            std::sort(el.second.begin(), el.second.end(), [](const BatchingUse &a, const BatchingUse &b) -> bool {
                return a.index < b.index;
            });

            int counter = 1;
            int last_slot = -1;
            for (size_t i = 0; i < 2 * el.second.size() && counter < el.second.size(); ++i)
            {
                auto cur_plus_one = (el.second[i % el.second.size()].index + 1) % slot_count;
                auto next = el.second[(i + 1) % el.second.size()].index % slot_count;
                // llvm::outs() << "\t\t\tcur+1: " << cur_plus_one << ", next: " << next;
                counter = cur_plus_one == next ? counter + 1 : 1;
                // llvm::outs() << " counter: " << counter << "\n";
                last_slot = i;
            }

            bool contiguous = !el.second.empty() && el.second.size() > 1 && counter == el.second.size();
            // if (!contiguous)
            // {
            //     llvm::outs() << "\t\tIgnoring because of non-contiguous indices. \n";
            // }

            // Check if it's a power of two
            auto n = el.second.size();
            auto k = std::log2(n);
            bool power_of_two = (k == (int)k);

            // if (!power_of_two)
            // {
            //     llvm::outs() << "\t\tIgnoring because its not a power of two.\n";
            // }

            if (contiguous && power_of_two)
            {
                // llvm::outs() << "\t\tApplying rotate-and-sum! \n";

                // The current implementation simply rotates everything to last_slot
                // then rotates that to target_slot
                // TODO: There are two possible optimizations of this rotate-and-sum implementation:
                //       1.) When the target slot falls within the contigous range, we should rotate there
                //       2.) When the target slot falls outside the contigous range,
                //           but there is a slot in the range that is a power-of-two distance away from the target slot,
                //           we should rotate to that slot, since the final rotation will be cheaper (non-composite)

                rewriter.setInsertionPoint(op);
                Value prev = origin;
                Value added;
                for (int i = n / 2; i > 0; i /= 2)
                {
                    auto rotated_down = rewriter.template create<fhe::RotateOp>(op.getLoc(), prev, i);
                    added = rewriter.template create<fhe::AddOp>(op.getLoc(), ValueRange({ prev, rotated_down }));
                    prev = added;
                }

                // now rotate to the target slot
                added = rewriter.template create<fhe::RotateOp>(op.getLoc(), added, last_slot - target_slot);

                // Now we need to replace ONE OF the operands that have this origin with "added" and REMOVE THE REST
                auto old_range = op.getX();
                SmallVector<Value> new_range = {};
                for (auto v : old_range)
                {
                    bool remove = false;
                    for (auto u : el.second)
                    {
                        if (v == u.occurrence) // we need to remove this
                            remove = true;
                    }
                    if (!remove)
                        new_range.push_back(v);
                }
                new_range.push_back(added);

                // TODO: This is probably all kinds of unsafe if there are multiple origins that are being replaced
                // in the same op
                op.getXMutable().assign(new_range);

                // llvm::outs() << "current function: ";
                // op->getParentOp()->print(llvm::outs());
                // llvm::outs() << '\n';
            }
        }
    }
    // else
    // {
    //     llvm::outs() << "Ignoring Internal Batching (target_slot = " << target_slot << ") for ";
    //     op.print(llvm::outs());
    //     llvm::outs() << " because it's return type is not BatchedSecret\n";
    // }
    return success();
}

void InternalOperandBatchingPass::runOnOperation()
{
    // Get the (default) block in the module's only region:
    auto &block = getOperation()->getRegion(0).getBlocks().front();
    IRRewriter rewriter(&getContext());

    for (auto f : llvm::make_early_inc_range(block.getOps<func::FuncOp>()))
    {
        // We must translate in order of appearance for this to work, so we walk manually
        if (f.walk([&](Operation *op) {
                 if (fhe::ExtractOp ex_op = llvm::dyn_cast_or_null<fhe::ExtractOp>(op))
                 {
                     auto target_slot = ex_op.getI().getLimitedValue();

                     for (auto o : ex_op.getOperation()->getOperands())
                     {
                         if (auto sub_op = llvm::dyn_cast_or_null<fhe::SubOp>(o.getDefiningOp()))
                             if (internalBatchArithmeticOperation<fhe::SubOp>(
                                     rewriter, &getContext(), sub_op, o, target_slot)
                                     .failed())
                                 return WalkResult::interrupt();
                         if (auto add_op = llvm::dyn_cast_or_null<fhe::AddOp>(o.getDefiningOp()))
                             if (internalBatchArithmeticOperation<fhe::AddOp>(
                                     rewriter, &getContext(), add_op, o, target_slot)
                                     .failed())
                                 return WalkResult::interrupt();
                         if (auto mul_op = llvm::dyn_cast_or_null<fhe::MultiplyOp>(o.getDefiningOp()))
                             if (internalBatchArithmeticOperation<fhe::MultiplyOp>(
                                     rewriter, &getContext(), mul_op, o, target_slot)
                                     .failed())
                                 return WalkResult::interrupt();
                         // TODO: Add support for relinearization!
                     }
                 }
                 // TODO: Add support for combine!
                 return WalkResult(success());
             }).wasInterrupted())
            signalPassFailure();
    }
}